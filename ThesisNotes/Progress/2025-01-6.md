#### HMMM
Today I should start marking out a scope for what I would want to achieve. Before the meeting with Martijn tomorrow I should come up with some (scope) related questions. 
#### What to Achieve
At the very least I want to achieve **sensor fusion using Bayesian inference**. The result should be some form of a world representation (object based?) that gets updated with new information. The method should be implemented on a Mirte Master and fuse data of a LiDAR and camera. I would like to use RxInfer, a Julia package, to implement the Bayesian inference method.  A cool addition would be to introduce an action dependency on the observations, as is done in active inference, to be able to use the Bayesian inference method to planning. Though the level of planning is not specified, lets see what is possible :)
#### How to Achieve
- [ ] **Working with RxInfer**
	- [x] Setup a Julia environment
	- [ ] Get familiar with Julia
	- [ ] Follow some demos/turtorials of RxInfer
	- [ ] Think about how to use Julia in within the ROS framework.
- [ ] **Working with the Mirte Master**
	- [ ] Getting started with ROS(1/2?) 
	- [ ] Getting camera data
	- [ ] Getting LiDAR data
- [ ] **Developing a method (If I continue with RxInfer, how would the world model look?)**
	A objected centered model would be most intuitive(?). Each object would be assigned a set of random variables describing different attributes of the object. I think that the observations should also be modeled by, a collection of, random variables. The difficulty might then come from a set of things:
		- When is a detection a (new) object?
		- How do I model interactions between object? Or more general,
		- How do I model interactions between random variables? This includes the mapping from random variables that describe the state of the world to those random variables describing the observation. 